{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf6a68b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT=\"\"\"You are an expert web dynamics annotator. You will receive:\n",
    "\n",
    "1. Current Observation: Accessibility tree before the action.\n",
    "2. Current Action: User action.\n",
    "3. Diff Tree: Actual ADDED, UPDATED, or DELETED changes in the accessibility tree.\n",
    "\n",
    "Your Goal:\n",
    "Translate the technical `Key Changes (Diff Tree)` into a natural language [Rationale] and [Next State] prediction.\n",
    "\n",
    "Guidelines for Response:\n",
    "1.  [Rationale]:\n",
    "   Convert each Diff Tree change into natural-language descriptions of what was added, removed, or updated. \n",
    "   Do NOT infer user intent or website logic. \n",
    "   Do NOT describe anything except what the diff explicitly shows.\n",
    "\n",
    "\n",
    "2.  State Description ([Next State]):\n",
    "    Then, generate a description of the next web state based on the changed parts you mentioned.\n",
    "    * High-Level & Functional: Do not say too much trivial details. Instead, give a high-level and functional description in detail after the action.\n",
    "    * Focus on Changes: Focus solely on describing the changes that will happen.\n",
    "    * Abstract & Generic: Avoid mentioning specific dynamic content (like specific prices, exact product titles) unless they are generic UI labels. For example, instead of saying \"The price updated to $25.00\", just say \"The price value is updated\".\n",
    "\n",
    "Keep both sections concise. Avoid long paragraphs or speculation.\n",
    "\n",
    "Response Format:\n",
    "[Rationale]\n",
    "Key changes in the accessibility tree based on [description of the action] would include:\n",
    "1. [Logic for change 1]\n",
    "2. [Logic for change 2]\n",
    "...\n",
    "\n",
    "[Next State] The expected effect is that:\n",
    "1. [Detail of the next state 1]\n",
    "2. [Detail of the next state 2]\n",
    "3. [Detail of the next state 3]\n",
    "...\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1facad19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds1 = load_dataset(\"LangAGI-Lab/world_model_for_wa_tao_dataset\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086de399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce40a276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key='AIzaSyCjJak0xp3uW8YnClPedUQBhsTaYZOdTXI')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86ee0200",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotating: 100%|██████████| 6841/6841 [1:47:17<00:00,  1.06it/s]  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "output_file = \"./sft_annotations_gemini.jsonl\"\n",
    "\n",
    "def annotate_single_item(i, item):\n",
    "    \"\"\"处理单个item的函数\"\"\"\n",
    "    current_obs = item.get('observation', '')\n",
    "    current_act = item.get('current_action', '')\n",
    "    \n",
    "    new_items_list = item.get('new_items', [])\n",
    "    updated_items_list = item.get('updated_items', []) \n",
    "    deleted_items_list = item.get('deleted_items', [])\n",
    "    \n",
    "    diff_tree = f\"ADDED: {new_items_list}\\nUPDATED: {updated_items_list}\\nDELETED: {deleted_items_list}\"\n",
    "    \n",
    "    user_input_content = f\"\"\"\n",
    "    Input:\n",
    "    Current Observation: {current_obs}\n",
    "    Current Action: {current_act}\n",
    "    Key Changes (Diff Tree): {diff_tree}\n",
    "    \"\"\"\n",
    "    \n",
    "    max_retries = 3\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            model = genai.GenerativeModel('models/gemini-2.5-flash')\n",
    "            response = model.generate_content(\n",
    "                f\"{SYSTEM_PROMPT}\\n\\n{user_input_content}\"\n",
    "            )\n",
    "            annotation = response.text\n",
    "            \n",
    "            return {\n",
    "                \"original_data_index\": i,\n",
    "                \"current_observation\": current_obs,\n",
    "                \"current_action\": current_act,\n",
    "                \"diff_tree_raw\": diff_tree,\n",
    "                \"generated_annotation\": annotation \n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            if attempt == max_retries - 1:\n",
    "                print(f\"\\nError on item {i}: {e}\")\n",
    "                return None\n",
    "            time.sleep(5)\n",
    "    \n",
    "    return None\n",
    "\n",
    "# 使用线程池并行处理\n",
    "max_workers = 10  # 根据API限制调整，Gemini通常可以设置较高\n",
    "with open(output_file, 'a', encoding='utf-8') as f:\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # 提交所有任务\n",
    "        futures = {\n",
    "            executor.submit(annotate_single_item, i, ds1[i]): i \n",
    "            for i in range(7903, len(ds1))\n",
    "        }\n",
    "        time.sleep(0.07) \n",
    "        # 处理完成的任务\n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Annotating\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "                f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "483ea57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json(\"./sft_annotations_gemini.jsonl\", lines=True)\n",
    "\n",
    "df.to_csv(\"./sft_annotations_gemini.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d107b5b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('sft_train.parquet')\n",
    "\n",
    "df['length'] = df['prompt'].str.len() + df['response'].str.len()\n",
    "\n",
    "print(\"长度统计:\")\n",
    "print(df['length'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['length'] = df['prompt'].str.len() + df['response'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050268f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
