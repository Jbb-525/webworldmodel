{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0b509228",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "df = pd.read_json(\"./sft_annotations_gemini.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8754b24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14744"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72f99f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-3B-Instruct\")\n",
    "\n",
    "token_counts = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e772ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction=\"\"\"You are an intelligent agent that predicts next state from given current action on a webpage, with your own logical reasoning.\n",
    "\n",
    "Here's the information you'll have:\n",
    "CURRENT OBSERVATION: The current web page's accessibility tree, a simplified representation of the webpage, providing key information.\n",
    "CURRENT ACTION: This is the current action that you performed to achieve the user's objective in the current web page's accessibility tree.\n",
    "The format of actions can fall into several categories:\n",
    "\n",
    "Page Operation Actions:\n",
    "```click [id]```: This action clicks on an element with a specific id on the webpage.\n",
    "```type [id] [content]```: Use this to type the content into the field with id. By default, the 'Enter' key is pressed after typing unless press_enter_after is set to 0, i.e., ```type [id] [content] [0]```.\n",
    "```hover [id]```: Hover over an element with id.\n",
    "```press [key_comb]```: Simulates the pressing of a key combination on the keyboard (e.g., Ctrl+v).\n",
    "```scroll [down]``` or ```scroll [up]```: Scroll the page up or down.\n",
    "\n",
    "Tab Management Actions:\n",
    "```new_tab```: Open a new, empty browser tab.\n",
    "```tab_focus [tab_index]```: Switch the browser's focus to a specific tab using its index.\n",
    "```close_tab```: Close the currently active tab.\n",
    "\n",
    "URL Navigation Actions:\n",
    "```goto [url]```: Navigate to a specific URL.\n",
    "```go_back```: Navigate to the previously viewed page.\n",
    "```go_forward```: Navigate to the next page (if a previous 'go_back' action was performed)\n",
    "\n",
    "CompletionAction:\n",
    " `stop[answer]`: Issue this action when you believe the task is complete. If the objective is to find a text-based answer, provide\n",
    " the answer in the bracket.\n",
    "\n",
    "You are required to predict the new changes that will occur on the webpage after the operation is performed. To be successful, it is very important to understand the effect of the current action on the next state of the webpage.\n",
    "\n",
    "Follow the following rules for next state prediction:\n",
    "1. In the **[Rationale]** part, identify and list the specific changes in the [accessibility tree] caused by the current action in natural language. Use a numbered list to detail these changes (e.g., items added, updated, or deleted).\n",
    "2. Then, generate the [Next State] description of the next web state based on the changed parts. \n",
    "3. Follow the Output Format structure below strictly.\n",
    "\n",
    "Response Format:\n",
    "[Rationale]\n",
    "Key changes in the accessibility tree based on [description of the action] would include:\n",
    "1. [Logic for change 1]\n",
    "2. [Logic for change 2]\n",
    "...\n",
    "\n",
    "[Next State] The expected effect is that:\n",
    "1. [Detail of the next state 1]\n",
    "2. [Detail of the next state 2]\n",
    "3. [Detail of the next state 3]\n",
    "...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2750b283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: 1000 items\n",
      "Processed: 2000 items\n",
      "Processed: 3000 items\n",
      "Processed: 4000 items\n",
      "Processed: 5000 items\n",
      "Processed: 6000 items\n",
      "Processed: 7000 items\n",
      "Processed: 8000 items\n",
      "Processed: 9000 items\n",
      "Processed: 10000 items\n",
      "Processed: 11000 items\n",
      "Processed: 12000 items\n",
      "Processed: 13000 items\n",
      "Processed: 14000 items\n",
      "\n",
      "Token counts distribution:\n",
      "  < 5000: 11587\n",
      "  > 5000: 3157\n"
     ]
    }
   ],
   "source": [
    "token_counts = []\n",
    "for i in range(len(df)):\n",
    "    text = instruction + df.iloc[i]['current_observation'] + df.iloc[i]['current_action'] + df.iloc[i]['generated_annotation']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_counts.append(len(tokens))\n",
    "    \n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"Processed: {i+1} items\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(f\"\\nToken counts distribution:\")\n",
    "print(f\"  < 5000: {sum(1 for x in token_counts if x < 5000)}\")\n",
    "print(f\"  > 5000: {sum(1 for x in token_counts if x >= 5000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "00d8af88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: 14744\n",
      "filtered: 11589\n",
      "removed: 3155\n",
      "ds1_filtered_len: 11589\n"
     ]
    }
   ],
   "source": [
    "filtered_indices = [i for i, count in enumerate(token_counts) if count <= 5000]\n",
    "\n",
    "print(f\"original: {len(df)}\")\n",
    "print(f\"filtered: {len(filtered_indices)}\")\n",
    "print(f\"removed: {len(df) - len(filtered_indices)}\")\n",
    "\n",
    "ds1_filtered = df.iloc[filtered_indices]\n",
    "\n",
    "print(f\"ds1_filtered_len: {len(ds1_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb64c89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved to: ./sft_train.parquet\n",
      "saved to: ./sft_test.parquet\n"
     ]
    }
   ],
   "source": [
    "sft_data = []\n",
    "\n",
    "for i in filtered_indices:\n",
    "    \n",
    "    input_text = f\"\"\"CURRENT OBSERVATION: {df.iloc[i]['current_observation']}\n",
    "CURRENT ACTION: {df.iloc[i]['current_action']}\"\"\"\n",
    "\n",
    "    prompt = instruction + \"\\n\\n Now, let's start the task. Here's the task for you: \\n\" + input_text\n",
    "\n",
    "    sft_data.append({\n",
    "        \"prompt\": prompt,\n",
    "        \"response\": df.iloc[i]['generated_annotation']\n",
    "    })\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "df = pd.DataFrame(sft_data)\n",
    "\n",
    "\n",
    "df[:11000].to_parquet(\"./sft_train.parquet\", index=False)\n",
    "print(\"saved to: ./sft_train.parquet\")\n",
    "df[11000:].to_parquet(\"./sft_test.parquet\", index=False)\n",
    "print(\"saved to: ./sft_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a89647c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    14500.000000\n",
      "mean      3445.090759\n",
      "std       1690.634378\n",
      "min        724.000000\n",
      "25%       1709.000000\n",
      "50%       3656.000000\n",
      "75%       4783.000000\n",
      "max       8110.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "token_counts = []\n",
    "df = pd.read_parquet('sft_train.parquet')\n",
    "\n",
    "for i in range(len(df)):\n",
    "    text = df.iloc[i]['prompt'] + df.iloc[i]['response']\n",
    "    tokens = tokenizer.encode(text)\n",
    "    token_counts.append(len(tokens))\n",
    "\n",
    "print(pd.Series(token_counts).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502b15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
